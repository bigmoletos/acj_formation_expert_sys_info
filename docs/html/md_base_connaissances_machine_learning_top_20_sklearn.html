<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.13"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>AJC Formation expert sys info - Option Data - Oct2024: top_20_sklearn</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">AJC Formation expert sys info - Option Data - Oct2024
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.13 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

</div><!-- top -->
<div class="header">
  <div class="headertitle">
<div class="title">top_20_sklearn </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p>Voici les 20 commandes les plus courantes de la bibliothèque Scikit-Learn pour l'apprentissage automatique:</p>
<ol type="1">
<li><b>fit</b>: Permet de remplir le modèle avec des données d'entraînement.</li>
<li><b>predict</b>: Permet de prédire les valeurs cibles pour les données d'entrée.</li>
<li><b>transform</b>: Permet de transformer les données d'entrée en un format compatible avec le modèle.</li>
<li><b>fit_transform</b>: Permet de remplir le modèle avec des données d'entraînement et de transformer les données d'entrée en un format compatible avec le modèle.</li>
<li><b>score</b>: Permet de calculer la précision du modèle sur les données de test.</li>
<li><b>get_params</b>: Permet d'obtenir les paramètres du modèle.</li>
<li><b>set_params</b>: Permet de définir les paramètres du modèle.</li>
<li><b>GridSearchCV</b>: Permet de rechercher les meilleurs paramètres pour un modèle donné.</li>
<li><b>RandomizedSearchCV</b>: Permet de rechercher les meilleurs paramètres pour un modèle donné en utilisant une recherche aléatoire.</li>
<li><b>cross_val_score</b>: Permet de calculer la précision du modèle en utilisant la validation croisée.</li>
<li><b>KFold</b>: Permet de diviser les données en k groupes pour la validation croisée.</li>
<li><b>train_test_split</b>: Permet de diviser les données en ensembles d'entraînement et de test.</li>
<li><b>Pipeline</b>: Permet de chaîner plusieurs étapes de traitement de données et de modélisation.</li>
<li><b>StandardScaler</b>: Permet de normaliser les données d'entrée.</li>
<li><b>MinMaxScaler</b>: Permet de mettre à l'échelle les données d'entrée entre 0 et 1.</li>
<li><b>OneHotEncoder</b>: Permet de convertir les variables catégorielles en variables binaires.</li>
<li><b>LabelEncoder</b>: Permet de convertir les variables catégorielles en variables numériques.</li>
<li><b>DecisionTreeClassifier</b>: Permet de créer un arbre de décision pour la classification.</li>
<li><b>RandomForestClassifier</b>: Permet de créer un modèle de forêt aléatoire pour la classification.</li>
<li><b>GradientBoostingClassifier</b>: Permet de créer un modèle de boosting de gradient pour la classification.</li>
</ol>
<ol type="1">
<li><b>fit</b>: Permet de remplir le modèle avec des données d’entraînement. from sklearn.linear_model import LinearRegression <h1>Créer un objet de modèle</h1>
</li>
</ol>
<p>model = LinearRegression() </p><h1>Remplir le modèle avec des données d'entraînement</h1>
<p>model.fit(X_train, y_train)</p>
<ol type="1">
<li><b>predict</b>: Permet de prédire les valeurs cibles pour les données d’entrée. <h1>Prédire les valeurs cibles pour les données d'entrée</h1>
</li>
</ol>
<p>y_pred = model.predict(X_test)</p>
<ol type="1">
<li><b>transform</b>: Permet de transformer les données d’entrée en un format compatible avec le modèle. from sklearn.preprocessing import StandardScaler <h1>Créer un objet de transformateur</h1>
</li>
</ol>
<p>scaler = StandardScaler() </p><h1>Transformer les données d'entrée en un format compatible avec le modèle</h1>
<p>X_train_scaled = scaler.transform(X_train)</p>
<ol type="1">
<li><b>fit_transform</b>: Permet de remplir le modèle avec des données d’entraînement et de transformer les données d’entrée en un format compatible avec le modèle. <h1>Remplir le modèle avec des données d'entraînement et transformer les données d'entrée en un format compatible avec le modèle</h1>
</li>
</ol>
<p>X_train_scaled = scaler.fit_transform(X_train)</p>
<ol type="1">
<li><b>score</b>: Permet de calculer la précision du modèle sur les données de test. <h1>Calculer la précision du modèle sur les données de test</h1>
</li>
</ol>
<p>model.score(X_test, y_test)</p>
<ol type="1">
<li><b>get_params</b>: Permet d’obtenir les paramètres du modèle. <h1>Obtenir les paramètres du modèle</h1>
</li>
</ol>
<p>model.get_params()</p>
<ol type="1">
<li><b>set_params</b>: Permet de définir les paramètres du modèle. <h1>Définir les paramètres du modèle</h1>
</li>
</ol>
<p>model.set_params(normalize=True)</p><ol type="1">
<li><b>GridSearchCV</b>: Permet de rechercher les meilleurs paramètres pour un modèle donné. from sklearn.model_selection import GridSearchCV from sklearn.svm import SVC <h1>Créer un objet de modèle</h1>
</li>
</ol>
<p>model = SVC() </p><h1>Définir les paramètres à rechercher</h1>
<p>param_grid = {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf']} </p><h1>Rechercher les meilleurs paramètres pour le modèle</h1>
<p>grid_search = GridSearchCV(model, param_grid) grid_search.fit(X_train, y_train)</p>
<ol type="1">
<li><b>RandomizedSearchCV</b>: Permet de rechercher les meilleurs paramètres pour un modèle donné en utilisant une recherche aléatoire. from sklearn.model_selection import RandomizedSearchCV from sklearn.ensemble import RandomForestClassifier <h1>Créer un objet de modèle</h1>
</li>
</ol>
<p>model = RandomForestClassifier() </p><h1>Définir les paramètres à rechercher</h1>
<p>param_distributions = {'n_estimators': [10, 100, 1000], 'max_depth': [None, 5, 10]} </p><h1>Rechercher les meilleurs paramètres pour le modèle</h1>
<p>random_search = RandomizedSearchCV(model, param_distributions) random_search.fit(X_train, y_train)</p>
<ol type="1">
<li><b>cross_val_score</b>: Permet de calculer la précision du modèle en utilisant la validation croisée. from sklearn.model_selection import cross_val_score from sklearn.tree import DecisionTreeClassifier <h1>Créer un objet de modèle</h1>
</li>
</ol>
<p>model = DecisionTreeClassifier() </p><h1>Calculer la précision du modèle en utilisant la validation croisée</h1>
<p>scores = cross_val_score(model, X, y, cv=5)</p>
<ol type="1">
<li><b>KFold</b>: Permet de diviser les données en k groupes pour la validation croisée. from sklearn.model_selection import KFold <h1>Créer un objet de diviseur de données</h1>
</li>
</ol>
<p>kf = KFold(n_splits=5) </p><h1>Diviser les données en k groupes pour la validation croisée</h1>
<p>for train_index, test_index in kf.split(X): X_train, X_test = X[train_index], X[test_index] y_train, y_test = y[train_index], y[test_index]</p>
<ol type="1">
<li><b>train_test_split</b>: Permet de diviser les données en ensembles d’entraînement et de test. from sklearn.model_selection import train_test_split <h1>Diviser les données en ensembles d'entraînement et de test</h1>
</li>
</ol>
<p>X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)</p>
<ol type="1">
<li><b>Pipeline</b>: Permet de chaîner plusieurs étapes de traitement de données et de modélisation. from sklearn.pipeline import Pipeline from sklearn.decomposition import PCA from sklearn.linear_model import LogisticRegression</li>
</ol>
<h1>Créer un objet de pipeline</h1>
<p>pipe = Pipeline([('pca', PCA()), ('logistic', LogisticRegression())])</p>
<h1>Remplir le pipeline avec des données d'entraînement et entraîner le modèle</h1>
<p>pipe.fit(X_train, y_train)</p>
<ol type="1">
<li><b>StandardScaler</b>: Permet de normaliser les données d’entrée. from sklearn.preprocessing import StandardScaler <h1>Créer un objet de normaliseur</h1>
</li>
</ol>
<p>scaler = StandardScaler() </p><h1>Normaliser les données d'entrée</h1>
<p>X_train_scaled = scaler.fit_transform(X_train)</p>
<ol type="1">
<li><b>MinMaxScaler</b>: Permet de mettre à l’échelle les données d’entrée entre 0 et 1. from sklearn.preprocessing import MinMaxScaler <h1>Créer un objet de mise à l'échelle</h1>
</li>
</ol>
<p>scaler = MinMaxScaler() </p><h1>Mettre à l'échelle les données d'entrée entre 0 et 1</h1>
<p>X_train_scaled = scaler.fit_transform(X_train)</p>
<ol type="1">
<li><b>OneHotEncoder</b>: Permet de convertir les variables catégorielles en variables binaires. from sklearn.preprocessing import OneHotEncoder <h1>Créer un objet de convertisseur</h1>
</li>
</ol>
<p>encoder = OneHotEncoder() </p><h1>Convertir les variables catégorielles en variables binaires</h1>
<p>X_train_encoded = encoder.fit_transform(X_train)</p>
<ol type="1">
<li><b>LabelEncoder</b>: Permet de convertir les variables catégorielles en variables numériques. from sklearn.preprocessing import LabelEncoder <h1>Créer un objet de convertisseur</h1>
</li>
</ol>
<p>encoder = LabelEncoder() </p><h1>Convertir les variables catégorielles en variables numériques</h1>
<p>y_train_encoded = encoder.fit_transform(y_train)</p>
<ol type="1">
<li><b>DecisionTreeClassifier</b>: Permet de créer un arbre de décision pour la classification. from sklearn.tree import DecisionTreeClassifier <h1>Créer un objet de modèle</h1>
</li>
</ol>
<p>model = DecisionTreeClassifier() </p><h1>Remplir le modèle avec des données d'entraînement</h1>
<p>model.fit(X_train, y_train)</p>
<ol type="1">
<li><b>RandomForestClassifier</b>: Permet de créer un modèle de forêt aléatoire pour la classification. from sklearn.ensemble import RandomForestClassifier <h1>Créer un objet de modèle</h1>
</li>
</ol>
<p>model = RandomForestClassifier() </p><h1>Remplir le modèle avec des données d'entraînement</h1>
<p>model.fit(X_train, y_train)</p>
<ol type="1">
<li><b>GradientBoostingClassifier</b>: Permet de créer un modèle de boosting de gradient pour la classification. from sklearn.ensemble import GradientBoostingClassifier <h1>Créer un objet de modèle</h1>
</li>
</ol>
<p>model = GradientBoostingClassifier() </p><h1>Remplir le modèle avec des données d'entraînement</h1>
<p>model.fit(X_train, y_train)</p>
<h1>VALEURS PAR DEFAUT</h1>
<p><b>GridSearchCV</b>: Les valeurs par défaut pour GridSearchCV sont:</p>
<p>estimator: None. param_grid: None. scoring: None. cv: None.</p>
<p><b>RandomForestClassifier</b>: Les valeurs par défaut pour RandomForestClassifier sont:</p>
<p>n_estimators: 100. criterion: “gini”. max_depth: None. min_samples_split: 2. min_samples_leaf: 1. min_weight_fraction_leaf: 0.0. max_features: “auto”. max_leaf_nodes: None. min_impurity_decrease: 0.0. min_impurity_split: None. bootstrap: True. oob_score: False. n_jobs: None. random_state: None. verbose: 0. warm_start: False. class_weight: None. ccp_alpha: 0.0. max_samples: None.</p>
<p><b>DecisionTreeClassifier</b>: Les valeurs par défaut pour DecisionTreeClassifier sont:</p>
<p>criterion: “gini”. splitter: “best”. max_depth: None. min_samples_split: 2. min_samples_leaf: 1. min_weight_fraction_leaf: 0.0. max_features: None. random_state: None. max_leaf_nodes: None. min_impurity_decrease: 0.0. min_impurity_split: None. class_weight: None. ccp_alpha: 0.0.</p>
<p><b>LogisticRegression</b>: Les valeurs par défaut pour LogisticRegression sont:</p>
<p>penalty: “l2”. dual: False. tol: 0.0001. C: 1.0. fit_intercept: True. intercept_scaling: 1. class_weight: None. random_state: None. solver: “lbfgs”. max_iter: 100. multi_class: “auto”. verbose: 0. warm_start: False. n_jobs: None. l1_ratio: None.</p>
<p><b>DecisionTreeRegressor</b>: Les valeurs par défaut pour DecisionTreeRegressor sont:</p>
<p>criterion: “mse”. splitter: “best”. max_depth: None. min_samples_split: 2. min_samples_leaf: 1. min_weight_fraction_leaf: 0.0. max_features: None. random_state: None. max_leaf_nodes: None. min_impurity_decrease: 0.0. min_impurity_split: None. ccp_alpha: 0.0.</p>
<p><b>GradientBoostingClassifier</b>: Les valeurs par défaut pour GradientBoostingClassifier sont:</p>
<p>loss: “deviance”. learning_rate: 0.1. n_estimators: 100. subsample: 1.0. criterion: “friedman_mse”. `min_samples </p>
</div></div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.13
</small></address>
</body>
</html>
